# Copyright (C) 2024-2025 Intel Corporation
# SPDX-License-Identifier: Apache-2.0
---
- name: Deploy Inference LLM Models
  hosts: kube_control_plane
  vars:
    ansible_python_interpreter: /usr/bin/python3
    helm_charts_base: "{{ lookup('env', 'PWD') }}/helm-charts"    
    remote_home_dir: "{{ lookup('env', 'PWD') }}/scripts"
    remote_helm_charts_base: "/tmp/helm-charts"
    ingress_file: "all_models_apisix_ingres_nginx.yaml"
    keycloak_url: "https://{{ secret_name }}"    
    uninstall_true: 'false'
    install_true: 'false'
    list_model_true: 'false'
    model_name_list: 'false'
    gpu_playbook: 'false'
    cpu_playbook: 'false'
    apisix_enabled: 'false'
    ingress_enabled: 'false'
    deploy_keycloak: 'no'
    tensor_parallel_size_vllm: 1
    gaudi_deployment: 'true'
    huggingface_model_id: 'false'
    hugging_face_model_deployment: 'false'
    huggingface_model_deployment_name: 'None'
    hugging_face_model_remove_name: 'false'
    gaudi_values_file: "{{ remote_helm_charts_base }}/vllm/gaudi-values.yaml"        
    huggingface_tensor_parellel_size: 'false'
    vllm_metrics_enabled: 'false'
  gather_facts: false
  any_errors_fatal: "{{ any_errors_fatal | default(true) }}"
  environment: "{{ proxy_disable_env | default({}) }}"
  tasks:
    - name: Print active tags for this task
      debug:
        var: ansible_run_tags
      tags: always
      run_once: true
    - name: Setup Environment
      block:
        - name: Ensure Python pip module is installed
          ansible.builtin.package:
            name: python3-pip
            state: present
          become: true
          tags: always
        - name: Install Kubernetes Python SDK
          ansible.builtin.pip:
            name: kubernetes
            state: present
            executable: /usr/bin/pip3
          become: true
          tags: always
        - name: Install Deployment Client
          ansible.builtin.shell: |
            curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
          args:
            executable: /bin/bash
          become: true
          tags: always    
        - name: Create/Update Kubernetes Secret for Hugging Face Token
          kubernetes.core.k8s:
            name: hugging-face-token
            namespace: default        
            kind: Secret
            definition:
              stringData:
                hugging-face-token: "{{ hugging_face_token }}"
            apply: yes
            state: present
          run_once: true
          when: hugging_face_token is defined    
          tags: always
        - name: Transfer Dependency files
          ansible.builtin.copy:
            src: "{{ helm_charts_base }}/"
            dest: "{{ remote_helm_charts_base }}/"
            mode: '0755'
            owner: "{{ ansible_user }}"
            group: "{{ ansible_user }}"
            remote_src: no
          tags: always
        - name: Transfer Dependency keycloak-realmcreationfile
          ansible.builtin.copy:
            src: "{{ remote_home_dir }}/"
            dest: "{{ remote_helm_charts_base }}/"
            mode: '0755'
            owner: "{{ ansible_user }}"
            group: "{{ ansible_user }}"
            remote_src: no
          tags: always
        - name: Ensure the script is executable
          file:
            path: "{{ remote_helm_charts_base }}/keycloak-realmcreation.sh"
            mode: '0755'
            owner: "{{ ansible_user }}"
            group: "{{ ansible_user }}"
          tags: always        
        - name: Update Dependencies for Auth-Apisix on Nodes
          ansible.builtin.command: helm dependency update "{{ remote_helm_charts_base }}/apisix-helm/"
          register: helm_dependency_update
          failed_when: helm_dependency_update.rc != 0
          when: apisix_enabled == "yes"
          tags: always      
    - name: Fetch the keycloak client secret
      block:
        - name: Fetch the keycloak client secret
          command: "{{ remote_helm_charts_base }}/keycloak-realmcreation.sh {{ secret_name }} {{ keycloak_admin_user }} {{ keycloak_admin_password }} {{ keycloak_client_id }}"
          register: script_output
        - name: Set Keycloak client fact
          set_fact:
            client_secret: "{{ script_output.stdout | regex_search('Client secret: (.*)') | join('') | regex_replace('^Client secret: ') }}"
          when: script_output.stdout is search('Client secret:')
        - name: Display Keycloak client
          debug:
            msg: "The client key is: {{ client_secret }}"        
      run_once: true
      when: deploy_keycloak == 'yes'
      tags: always
            
    - name: Print model_name_list
      debug:
        var: model_name_list
      tags: always
      run_once: true
    - name: Deploy Llama8b LLM Model
      block:
        - name: Delete Ingress resource Llama8b from default namespace
          kubernetes.core.k8s:
            kind: Ingress
            namespace: default
            name: vllm-llama-8b-ingress
            state: absent          
          tags: install-llama-8b
        - name: Delete Ingress resource Llama8b from auth-apisix namespace
          kubernetes.core.k8s:
            kind: Ingress
            namespace: auth-apisix
            name: vllm-llama-8b-ingress
            state: absent
          tags: install-llama-8b          
        - name: Deploy LLM model Llama8b
          ansible.builtin.command: >-
            helm upgrade --install vllm-llama-8b "{{ remote_helm_charts_base }}/vllm"
            --set LLM_MODEL_ID="meta-llama/Llama-3.1-8B-Instruct"
            --set global.monitoring="{{ vllm_metrics_enabled }}"
            --set svcmonitor.enabled="{{ vllm_metrics_enabled }}"
            --set global.HUGGINGFACEHUB_API_TOKEN={{ hugging_face_token }}                        
            {% if apisix_enabled %}
              --set apisix.enabled={{ apisix_enabled }}
            {% endif %}
            {% if gaudi_deployment %}
              --set tensor_parallel_size={{ tensor_parallel_size_vllm }}
              --values {{ gaudi_values_file }}              
            {% endif %}
            {% if ingress_enabled %}
              --set ingress.enabled={{ ingress_enabled }}
              --set ingress.host={{ secret_name }}
              --set ingress.secretname={{ secret_name }}
            {% endif %}
            {% if deploy_keycloak == 'yes' and apisix_enabled %}
              --set oidc.client_id={{ keycloak_client_id | default('') }}
              --set oidc.client_secret={{ client_secret | default('') }}
            {% endif %}
            --force             
          register: helm_upgrade_install_model_deployment
          failed_when: helm_upgrade_install_model_deployment.rc != 0
          tags: install-llama-8b
      run_once: true
      when:                
        - model_name_list is defined        
        - "'llama-8b' in (model_name_list | regex_replace(',', ' ') | split())"
        - install_true == 'true'


    - name: Check if vllm-llama-8b Model is deployed
      ansible.builtin.command:
        cmd: "helm list --filter vllm-llama-8b --short"
      register: helm_release_installed
      ignore_errors: true
      run_once: true
      tags: uninstall-llama-8b
    - name: Uninstall vllm-llama-8b Model 
      ansible.builtin.command:
        cmd: "helm uninstall vllm-llama-8b"
      run_once: true
      tags: uninstall-llama-8b
      when:
        - "'llama-8b' in (model_name_list | regex_replace(',', ' ') | split())"
        - uninstall_true == 'true'
        - helm_release_installed.stdout != ""
    

    - name: Deploy "{{ huggingface_model_id }}" LLM Model
      block:
        - name: Delete Ingress resource "{{ huggingface_model_id }}" from default namespace
          kubernetes.core.k8s:
            kind: Ingress
            namespace: default
            name: "{{huggingface_model_deployment_name}}-ingress"
            state: absent
          tags: "install-{{ huggingface_model_deployment_name }}"
        - name: Delete Ingress resource "{{ huggingface_model_id }}" from auth-apisix namespace
          kubernetes.core.k8s:
            kind: Ingress
            namespace: auth-apisix
            name: "{{huggingface_model_deployment_name}}-ingress"
            state: absent
          tags: "install-{{ huggingface_model_deployment_name }}"
        - name: Deploy LLM model "{{ huggingface_model_id }}"
          ansible.builtin.command: >-
            helm upgrade --install "{{huggingface_model_deployment_name}}" "{{ remote_helm_charts_base }}/vllm"
            --set LLM_MODEL_ID="{{ huggingface_model_id }}"
            --set global.monitoring="{{ vllm_metrics_enabled }}"
            --set svcmonitor.enabled="{{ vllm_metrics_enabled }}"
            --set global.HUGGINGFACEHUB_API_TOKEN={{ hugging_face_token }}                        
            {% if apisix_enabled %}
              --set apisix.enabled={{ apisix_enabled }}
            {% endif %}
            {% if gaudi_deployment|lower == "true" %}
              --set tensor_parallel_size={{ huggingface_tensor_parellel_size }}
              --values {{ gaudi_values_file }}              
            {% endif %}
            {% if ingress_enabled %}
              --set ingress.enabled={{ ingress_enabled }}
              --set ingress.host={{ secret_name }}
              --set ingress.secretname={{ secret_name }}
            {% endif %}
            {% if deploy_keycloak == 'yes' and apisix_enabled %}
              --set oidc.client_id={{ keycloak_client_id | default('') }}
              --set oidc.client_secret={{ client_secret | default('') }}
            {% endif %}
            --force             
          register: helm_upgrade_install_model_deployment
          failed_when: helm_upgrade_install_model_deployment.rc != 0
      run_once: true
      tags: "install-{{ huggingface_model_deployment_name }}"
      when:                        
        - hugging_face_model_deployment == 'true'
        - install_true == 'true'
        
                
    
    - name: Check if "{{ hugging_face_model_remove_name }}" Model is deployed
      ansible.builtin.command:
        cmd: "helm list --filter {{ hugging_face_model_remove_name }} --short"
      register: helm_release_installed
      ignore_errors: true
      run_once: true
      tags: "uninstall-{{ hugging_face_model_remove_name }}"
    - name: Uninstall "{{ hugging_face_model_remove_name }}" Model 
      ansible.builtin.command:
        cmd: "helm uninstall {{ hugging_face_model_remove_name }}"
      run_once: true
      tags: "uninstall-{{ hugging_face_model_remove_name }}"
      when:        
        - uninstall_true == 'true'
        - hugging_face_model_remove_deployment == 'true'
        - helm_release_installed.stdout != ""
    
    - name: Deploy Llama70b LLM Model
      block:
        - name: Delete Ingress resource Llama70b from default namespace
          kubernetes.core.k8s:
            kind: Ingress
            namespace: default
            name: vllm-llama-70b-ingress
            state: absent
          tags: install-llama-70b
        - name: Delete Ingress resource Llama70b from auth-apisix namespace
          tags: install-llama-70b
          kubernetes.core.k8s:
            kind: Ingress
            namespace: auth-apisix
            name: vllm-llama-70b-ingress
            state: absent
        - name: Deploy LLM model Llama70b
          ansible.builtin.command: >-
            helm upgrade --install vllm-llama-70b "{{ remote_helm_charts_base }}/vllm"
            --set LLM_MODEL_ID="meta-llama/Llama-3.1-70B-Instruct"
            --set global.monitoring="{{ vllm_metrics_enabled }}"
            --set svcmonitor.enabled="{{ vllm_metrics_enabled }}"
            --set global.HUGGINGFACEHUB_API_TOKEN={{ hugging_face_token }}            
            --set tensor_parallel_size=4
            {% if apisix_enabled %}
              --set apisix.enabled={{ apisix_enabled }}
            {% endif %}
            {% if gaudi_deployment %}
              --values {{ gaudi_values_file }}
            {% endif %}
            {% if ingress_enabled %}
              --set ingress.enabled={{ ingress_enabled }}
              --set ingress.host={{ secret_name }}
              --set ingress.secretname={{ secret_name }}
            {% endif %}
            {% if deploy_keycloak == 'yes' and apisix_enabled %}
              --set oidc.client_id={{ keycloak_client_id | default('') }}
              --set oidc.client_secret={{ client_secret | default('') }}
            {% endif %}
            --force             
          register: helm_upgrade_install_model_deployment
          failed_when: helm_upgrade_install_model_deployment.rc != 0
      run_once: true
      tags: install-llama-70b
      when:
        - '"llama-70b" in model_name_list'
        - install_true == 'true'


    - name: Check if vllm-llama-70b Model is deployed
      ansible.builtin.command:
        cmd: "helm list --filter vllm-llama-70b --short"
      register: helm_release_installed
      ignore_errors: true
      run_once: true
      tags: uninstall-llama-70b
    - name: Uninstall llama-70b Model 
      ansible.builtin.command:
        cmd: "helm uninstall vllm-llama-70b"
      run_once: true
      tags: uninstall-llama-70b
      when:
        - "'llama-70b' in model_name_list"
        - uninstall_true == 'true'
        - helm_release_installed.stdout != ""

    - name: Deploy Llama3-3-70b LLM Model
      block:
        - name: Delete Ingress resource Llama3.3-70b from default namespace
          kubernetes.core.k8s:
            kind: Ingress
            namespace: default
            name: vllm-llama-3-3-70b-ingress
            state: absent          
          tags: install-llama-3-3-70b
        - name: Delete Ingress resource Llama3-3-70b from auth-apisix namespace
          kubernetes.core.k8s:
            kind: Ingress
            namespace: auth-apisix
            name: vllm-llama-3-3-70b-ingress
            state: absent
          tags: install-llama-3-3-70b          
        - name: Deploy LLM model Llama3-3-70b
          ansible.builtin.command: >-
            helm upgrade --install vllm-llama-3-3-70b "{{ remote_helm_charts_base }}/vllm"
            --set LLM_MODEL_ID="meta-llama/Llama-3.3-70B-Instruct"
            --set global.monitoring="{{ vllm_metrics_enabled }}"
            --set svcmonitor.enabled="{{ vllm_metrics_enabled }}"
            --set global.HUGGINGFACEHUB_API_TOKEN={{ hugging_face_token }}                        
            {% if apisix_enabled %}
              --set apisix.enabled={{ apisix_enabled }}
            {% endif %}
            {% if gaudi_deployment %}
              --set tensor_parallel_size=4
              --values {{ gaudi_values_file }}              
            {% endif %}
            {% if ingress_enabled %}
              --set ingress.enabled={{ ingress_enabled }}
              --set ingress.host={{ secret_name }}
              --set ingress.secretname={{ secret_name }}
            {% endif %}
            {% if deploy_keycloak == 'yes' and apisix_enabled %}
              --set oidc.client_id={{ keycloak_client_id | default('') }}
              --set oidc.client_secret={{ client_secret | default('') }}
            {% endif %}
            {{ helm_proxy_args | default('') }}
            --force             
          register: helm_upgrade_install_model_deployment
          failed_when: helm_upgrade_install_model_deployment.rc != 0
          tags: install-llama-3-3-70b
      run_once: true
      when:
        - model_name_list is defined
        - "'llama-3-3-70b' in (model_name_list | regex_replace(',', ' ') | split())"
        - install_true == 'true'


    - name: Check if vllm-llama-3-3-70b Model is deployed
      ansible.builtin.command:
        cmd: "helm list --filter vllm-llama-3-3-70b --short"
      register: helm_release_installed
      ignore_errors: true
      run_once: true
      tags: uninstall-llama-3-3-70b
    - name: Uninstall vllm-llama-3-3-70b Model 
      ansible.builtin.command:
        cmd: "helm uninstall vllm-llama-3-3-70b"
      run_once: true
      tags: uninstall-llama-3-3-70b
      when:
        - "'llama-3.3-70b' in (model_name_list | regex_replace(',', ' ') | split())"
        - uninstall_true == 'true'
        - helm_release_installed.stdout != ""


    - name: Deploy Mixtral7b LLM Model
      block:
        - name: Delete Ingress resource Mixtral7b from default namespace
          tags: install-mixtral-8x-7b
          kubernetes.core.k8s:
            kind: Ingress
            namespace: default
            name: vllm-mixtral-7b-ingress
            state: absent          
        - name: Delete Ingress resource Mixtral7b from auth-apisix namespace
          tags: install-mixtral-8x-7b
          kubernetes.core.k8s:
            kind: Ingress
            namespace: auth-apisix
            name: vllm-mixtral-7b-ingress
            state: absent
        - name: Deploy LLM model Mixtral7b
          ansible.builtin.command: >-
            helm upgrade --install vllm-mixtral-7b "{{ remote_helm_charts_base }}/vllm"
            --set LLM_MODEL_ID="mistralai/Mixtral-8x7B-Instruct-v0.1"
            --set global.monitoring="{{ vllm_metrics_enabled }}"
            --set svcmonitor.enabled="{{ vllm_metrics_enabled }}"
            --set global.HUGGINGFACEHUB_API_TOKEN={{ hugging_face_token }}            
            --set tensor_parallel_size={{ tensor_parallel_size_vllm }}
            {% if apisix_enabled %}
              --set apisix.enabled={{ apisix_enabled }}
            {% endif %}
            {% if gaudi_deployment %}
              --values {{ gaudi_values_file }}
            {% endif %}
            {% if ingress_enabled %}
              --set ingress.enabled={{ ingress_enabled }}
              --set ingress.host={{ secret_name }}
              --set ingress.secretname={{ secret_name }}
            {% endif %}
            {% if deploy_keycloak == 'yes' and apisix_enabled %}
              --set oidc.client_id={{ keycloak_client_id | default('') }}
              --set oidc.client_secret={{ client_secret | default('') }}
            {% endif %}
            --force             
          register: helm_upgrade_install_model_deployment
          failed_when: helm_upgrade_install_model_deployment.rc != 0
      run_once: true
      tags: install-mixtral-8x-7b
      when:
        - '"mixtral-8x-7b" in model_name_list'
        - install_true == 'true'


    - name: Check if Mixtral7b Model is deployed
      ansible.builtin.command:
        cmd: "helm list --filter vllm-mixtral-7b --short"
      register: helm_release_installed
      ignore_errors: true
      run_once: true
      tags: uninstall-mixtral-8x-7b
    - name: Uninstall mixtral-8x-7b Model 
      ansible.builtin.command:
        cmd: "helm uninstall vllm-mixtral-7b"
      run_once: true
      tags: uninstall-mixtral-8x-7b
      when:
        - "'mixtral-8x-7b' in model_name_list"
        - uninstall_true == 'true'
        - helm_release_installed.stdout != ""


    - name: Deploy codellama LLM Model
      block:
        - name: Delete Ingress resource Codellama from default namespace
          tags: install-codellama-34b
          kubernetes.core.k8s:
            kind: Ingress
            namespace: default
            name: vllm-codellama-ingress
            state: absent
        - name: Delete Ingress resource Codellama from auth-apisix namespace
          tags: install-codellama-34b
          kubernetes.core.k8s:
            kind: Ingress
            namespace: auth-apisix
            name: vllm-codellama-ingress
            state: absent
        - name: Deploy LLM model codellama
          ansible.builtin.command: >-
            helm upgrade --install vllm-codellama "{{ remote_helm_charts_base }}/vllm"
            --set LLM_MODEL_ID="codellama/CodeLlama-34b-Instruct-hf"
            --set global.monitoring="{{ vllm_metrics_enabled }}"
            --set svcmonitor.enabled="{{ vllm_metrics_enabled }}"
            --set global.HUGGINGFACEHUB_API_TOKEN={{ hugging_face_token }}            
            --set tensor_parallel_size={{ tensor_parallel_size_vllm }}
            {% if apisix_enabled %}
              --set apisix.enabled={{ apisix_enabled }}
            {% endif %}
            {% if gaudi_deployment %}
              --values {{ gaudi_values_file }}
            {% endif %}
            {% if ingress_enabled %}
              --set ingress.enabled={{ ingress_enabled }}
              --set ingress.host={{ secret_name }}
              --set ingress.secretname={{ secret_name }}
            {% endif %}
            {% if deploy_keycloak == 'yes' and apisix_enabled %}
              --set oidc.client_id={{ keycloak_client_id | default('') }}
              --set oidc.client_secret={{ client_secret | default('') }}
            {% endif %}
            --force             
          register: helm_upgrade_install_model_deployment
          failed_when: helm_upgrade_install_model_deployment.rc != 0
      run_once: true
      tags: install-codellama-34b
      when:
        - '"codellama-34b" in model_name_list'
        - install_true == 'true'
    - name: Check if codellama-34b Model is deployed
      ansible.builtin.command:
        cmd: "helm list --filter vllm-codellama --short"
      register: helm_release_installed
      ignore_errors: true
      run_once: true
      tags: uninstall-codellama-34b
    - name: Uninstall codellama-34b Model 
      ansible.builtin.command:
        cmd: "helm uninstall vllm-codellama"
      run_once: true
      tags: uninstall-codellama-34b
      when:
        - "'codellama-34b' in model_name_list"
        - uninstall_true == 'true'
        - helm_release_installed.stdout != ""


    - name: Deploy Faclon3 7b LLM Model
      block:
        - name: Delete Ingress resource Falcon3 7b from default namespace
          tags: install-falcon3-7b
          kubernetes.core.k8s:
            kind: Ingress
            namespace: default
            name: vllm-falcon3-7b-ingress
            state: absent
        - name: Delete Ingress resource Falcon3 7b from auth-apisix namespace
          tags: install-falcon3-7b
          kubernetes.core.k8s:
            kind: Ingress
            namespace: auth-apisix
            name: vllm-falcon3-7b-ingress
            state: absent
        - name: Deploy LLM model codellama
          ansible.builtin.command: >-
            helm upgrade --install vllm-falcon3-7b "{{ remote_helm_charts_base }}/vllm"
            --set LLM_MODEL_ID="tiiuae/Falcon3-7B-Instruct"
            --set global.monitoring="{{ vllm_metrics_enabled }}"
            --set svcmonitor.enabled="{{ vllm_metrics_enabled }}"
            --set global.HUGGINGFACEHUB_API_TOKEN={{ hugging_face_token }}            
            --set tensor_parallel_size={{ tensor_parallel_size_vllm }}
            {% if apisix_enabled %}
              --set apisix.enabled={{ apisix_enabled }}
            {% endif %}
            {% if gaudi_deployment %}
              --values {{ gaudi_values_file }}
            {% endif %}
            {% if ingress_enabled %}
              --set ingress.enabled={{ ingress_enabled }}
              --set ingress.host={{ secret_name }}
              --set ingress.secretname={{ secret_name }}
            {% endif %}
            {% if deploy_keycloak == 'yes' and apisix_enabled %}
              --set oidc.client_id={{ keycloak_client_id | default('') }}
              --set oidc.client_secret={{ client_secret | default('') }}
            {% endif %}
            --force             
          register: helm_upgrade_install_model_deployment
          failed_when: helm_upgrade_install_model_deployment.rc != 0
      run_once: true
      tags: install-falcon3-7b
      when:
        - '"falcon3-7b" in model_name_list'
        - install_true == 'true'
    - name: Check if Faclon3 7b Model is deployed
      ansible.builtin.command:
        cmd: "helm list --filter vllm-falcon3-7b --short"
      register: helm_release_installed
      ignore_errors: true
      run_once: true
      tags: uninstall-falcon3-7b
    - name: Uninstall Faclon3 7b Model 
      ansible.builtin.command:
        cmd: "helm uninstall vllm-falcon3-7b"
      run_once: true
      tags: uninstall-falcon3-7b
      when:
        - "'falcon3-7b' in model_name_list"
        - uninstall_true == 'true'
        - helm_release_installed.stdout != ""


    - name: Deploy Mistral_7b LLM Model
      block:
        - name: Delete Ingress resource Mistral 7b from default namespace
          tags: install-mistral-7b
          kubernetes.core.k8s:
            kind: Ingress
            namespace: default
            name: vllm-mistral-7b-ingress
            state: absent
        - name: Delete Ingress resource Mistral 7b from auth-apisix namespace
          tags: install-mistral-7b
          kubernetes.core.k8s:
            kind: Ingress
            namespace: auth-apisix
            name: vllm-mistral-7b-ingress
            state: absent
        - name: Deploy LLM model Mistral_7b
          ansible.builtin.command: >-
            helm upgrade --install vllm-mistral-7b "{{ remote_helm_charts_base }}/vllm"
            --set LLM_MODEL_ID="mistralai/Mistral-7B-Instruct-v0.3"
            --set global.monitoring="{{ vllm_metrics_enabled }}"
            --set svcmonitor.enabled="{{ vllm_metrics_enabled }}"
            --set global.HUGGINGFACEHUB_API_TOKEN={{ hugging_face_token }}            
            --set tensor_parallel_size={{ tensor_parallel_size_vllm }}
            {% if apisix_enabled %}
              --set apisix.enabled={{ apisix_enabled }}
            {% endif %}
            {% if gaudi_deployment %}
              --values {{ gaudi_values_file }}
            {% endif %}
            {% if ingress_enabled %}
              --set ingress.enabled={{ ingress_enabled }}
              --set ingress.host={{ secret_name }}
              --set ingress.secretname={{ secret_name }}
            {% endif %}
            {% if deploy_keycloak == 'yes' and apisix_enabled %}
              --set oidc.client_id={{ keycloak_client_id | default('') }}
              --set oidc.client_secret={{ client_secret | default('') }}
            {% endif %}
            --force             
          register: helm_upgrade_install_model_deployment
          failed_when: helm_upgrade_install_model_deployment.rc != 0
      run_once: true
      tags: install-mistral-7b
      when:
        - '"mistral-7b" in model_name_list'
        - install_true == 'true'
    - name: Check if Mistral_7b Model is deployed
      ansible.builtin.command:
        cmd: "helm list --filter vllm-mistral-7b --short"
      register: helm_release_installed
      ignore_errors: true
      run_once: true
      tags: uninstall-mistral-7b
    - name: Uninstall Mistral_7b Model 
      ansible.builtin.command:
        cmd: "helm uninstall vllm-mistral-7b"
      run_once: true
      tags: uninstall-mistral-7b
      when:
        - "'mistral-7b' in model_name_list"
        - uninstall_true == 'true'
        - helm_release_installed.stdout != ""


    - name: Deploy tei LLM Model
      block:
        - name: Delete existing Ingress resource tei in auth-apisix namespace
          tags: install-tei
          kubernetes.core.k8s:
            kind: Ingress
            namespace: auth-apisix
            name: vllm-tei-ingress
            state: absent
        - name: Delete existing Ingress resource tei in default namespace
          tags: install-tei
          kubernetes.core.k8s:
            kind: Ingress
            namespace: default
            name: vllm-tei-ingress
            state: absent                
        - name: Deploy LLM model tei
          ansible.builtin.command: >-
            helm upgrade --install vllm-tei "{{ remote_helm_charts_base }}/tei"
            --set EMBEDDING_MODEL_ID="BAAI/bge-base-en-v1.5"            
            --set global.HUGGINGFACEHUB_API_TOKEN={{ hugging_face_token }}            
            --set tensor_parallel_size={{ tensor_parallel_size_vllm }}
            {% if apisix_enabled %}
              --set apisix.enabled={{ apisix_enabled }}
            {% endif %}
            {% if gaudi_deployment %}
              --values "{{ remote_helm_charts_base }}/tei/gaudi-values.yaml"
            {% endif %}
            {% if ingress_enabled %}
              --set ingress.enabled={{ ingress_enabled }}
              --set ingress.host={{ secret_name }}
              --set ingress.secretname={{ secret_name }}
            {% endif %}
            {% if deploy_keycloak == 'yes' and apisix_enabled %}
              --set oidc.client_id={{ keycloak_client_id | default('') }}
              --set oidc.client_secret={{ client_secret | default('') }}
            {% endif %}
            --set teirerank.namespace=default            
            --force             
          register: helm_upgrade_install_model_deployment
          failed_when: helm_upgrade_install_model_deployment.rc != 0
      run_once: true
      tags: install-tei
      when:
        - "'tei' in model_name_list"
        - install_true == 'true'
    - name: Check if tei Model is deployed
      ansible.builtin.command:
        cmd: "helm list --filter vllm-tei --short"
      register: helm_release_installed
      ignore_errors: true
      run_once: true
      tags: uninstall-tei
    - name: Uninstall tei Model 
      ansible.builtin.command:
        cmd: "helm uninstall vllm-tei"
      run_once: true
      tags: uninstall-tei
      when:        
        - "'tei' in model_name_list"
        - uninstall_true == 'true'
        - helm_release_installed.stdout != ""
   
    - name: Deploy teirerank LLM Model
      block:
        - name: Delete Ingress resource Teirerank from default namespace
          tags: install-rerank
          kubernetes.core.k8s:
            kind: Ingress
            namespace: default
            name: vllm-teirerank-ingress
            state: absent
        - name: Delete Ingress resource Teirerank from auth-apisix namespace
          tags: install-rerank
          kubernetes.core.k8s:
            kind: Ingress
            namespace: auth-apisix
            name: vllm-teirerank-ingress
            state: absent
        - name: Deploy LLM model teirerank
          ansible.builtin.command: >-
            helm upgrade --install vllm-teirerank "{{ remote_helm_charts_base }}/teirerank"
            --set RERANK_MODEL_ID="BAAI/bge-reranker-base"
            --set global.HUGGINGFACEHUB_API_TOKEN={{ hugging_face_token }}            
            --set tensor_parallel_size={{ tensor_parallel_size_vllm }}
            {% if apisix_enabled %}
              --set apisix.enabled={{ apisix_enabled }}
            {% endif %}
            {% if gaudi_deployment %}
              --values "{{ remote_helm_charts_base }}/teirerank/gaudi-values.yaml"
            {% endif %}
            {% if ingress_enabled %}
              --set ingress.enabled={{ ingress_enabled }}
              --set ingress.host={{ secret_name }}
              --set ingress.secretname={{ secret_name }}
            {% endif %}
            {% if deploy_keycloak == 'yes' and apisix_enabled %}
              --set oidc.client_id={{ keycloak_client_id | default('') }}
              --set oidc.client_secret={{ client_secret | default('') }}
            {% endif %}
            --set teirerank.namespace=default
            --force             
          register: helm_upgrade_install_model_deployment
          failed_when: helm_upgrade_install_model_deployment.rc != 0
      run_once: true
      tags: install-rerank
      when:
        - "'rerank' in model_name_list"        
        - install_true == 'true'
    - name: Check if teirerank Model is deployed
      ansible.builtin.command:
        cmd: "helm list --filter vllm-teirerank --short"
      register: helm_release_installed
      ignore_errors: true
      run_once: true
      tags: uninstall-rerank
    - name: Uninstall teirerank Model 
      ansible.builtin.command:
        cmd: "helm uninstall vllm-teirerank"
      run_once: true
      tags: uninstall-rerank
      when:        
        - "'rerank' in model_name_list"   
        - uninstall_true == 'true'
        - helm_release_installed.stdout != ""

    - name: Deploy Deepkseek R1 Distill Qwen 32b LLM Model
      block:
        - name: Delete Ingress resource Deepkseek R1 Distill Qwen 32b from default namespace
          tags: install-deepseek-r1-distill-qwen-32b
          kubernetes.core.k8s:
            kind: Ingress
            namespace: default
            name: vllm-deepkseek-r1-qwen-32b-ingress
            state: absent          
          run_once: true
        - name: Delete Ingress resource Deepkseek R1 Distill Qwen 32b from auth-apisix namespace
          tags: install-deepseek-r1-distill-qwen-32b
          kubernetes.core.k8s:
            kind: Ingress
            namespace: auth-apisix
            name: vllm-deepkseek-r1-qwen-32b-ingress
            state: absent
          run_once: true
        - name: Deploy LLM model Deepkseek R1 Distill Qwen 32b
          ansible.builtin.command: >-
            helm upgrade --install vllm-deepkseek-r1-qwen-32b "{{ remote_helm_charts_base }}/vllm"
            --set LLM_MODEL_ID="deepseek-ai/DeepSeek-R1-Distill-Qwen-32B"
            --set global.monitoring="{{ vllm_metrics_enabled }}"
            --set svcmonitor.enabled="{{ vllm_metrics_enabled }}"
            --set global.HUGGINGFACEHUB_API_TOKEN={{ hugging_face_token }}                        
            {% if apisix_enabled %}
              --set apisix.enabled={{ apisix_enabled }}
            {% endif %}
            {% if gaudi_deployment %}
              --set tensor_parallel_size=2
              --values {{ gaudi_values_file }}              
            {% endif %}
            {% if ingress_enabled %}
              --set ingress.enabled={{ ingress_enabled }}
              --set ingress.host={{ secret_name }}
              --set ingress.secretname={{ secret_name }}
            {% endif %}
            {% if deploy_keycloak == 'yes' and apisix_enabled %}
              --set oidc.client_id={{ keycloak_client_id | default('') }}
              --set oidc.client_secret={{ client_secret | default('') }}
            {% endif %}
            --force             
          register: helm_upgrade_install_model_deployment
          failed_when: helm_upgrade_install_model_deployment.rc != 0
      run_once: true    
      tags: install-deepseek-r1-distill-qwen-32b
      when:                
        - "'deepseek-r1-distill-qwen-32b' in (model_name_list | regex_replace(',', ' ') | split())"        
        - install_true == 'true'


    - name: Check if vllm-deepkseek-r1-qwen-32b Model is deployed
      ansible.builtin.command:
        cmd: "helm list --filter vllm-deepkseek-r1-qwen-32b --short"
      register: helm_release_installed
      ignore_errors: true
      run_once: true
      tags: uninstall-deepseek-r1-distill-qwen-32b
    - name: Uninstall vllm-deepkseek-r1-qwen-32b Model 
      ansible.builtin.command:
        cmd: "helm uninstall vllm-deepkseek-r1-qwen-32b"
      run_once: true
      tags: uninstall-deepseek-r1-distill-qwen-32b
      when:
        - "'deepseek-r1-distill-qwen-32b' in (model_name_list | regex_replace(',', ' ') | split())"
        - uninstall_true == 'true'
        - helm_release_installed.stdout != ""



    - name: Deploy Deepkseek R1 Distill Llama 8b LLM Model
      block:
        - name: Delete Ingress resource Deepkseek R1 Distill Llama 8b from default namespace
          tags: install-deepseek-r1-distill-llama8b
          kubernetes.core.k8s:
            kind: Ingress
            namespace: default
            name: vllm-deepkseek-r1-llama-8b-ingress
            state: absent          
        - name: Delete Ingress resource Deepkseek R1 Distill Llama 8b from auth-apisix namespace
          tags: install-deepseek-r1-distill-llama8b
          kubernetes.core.k8s:
            kind: Ingress
            namespace: auth-apisix
            name: vllm-deepkseek-r1-llama-8b-ingress
            state: absent          
        - name: Deploy LLM model Deepkseek R1 Distill Llama 8b
          ansible.builtin.command: >-
            helm upgrade --install vllm-deepkseek-r1-llama-8b "{{ remote_helm_charts_base }}/vllm"
            --set LLM_MODEL_ID="deepseek-ai/DeepSeek-R1-Distill-Llama-8B"
            --set global.monitoring="{{ vllm_metrics_enabled }}"
            --set svcmonitor.enabled="{{ vllm_metrics_enabled }}"
            --set global.HUGGINGFACEHUB_API_TOKEN={{ hugging_face_token }}                        
            {% if apisix_enabled %}
              --set apisix.enabled={{ apisix_enabled }}
            {% endif %}
            {% if gaudi_deployment %}
              --set tensor_parallel_size={{ tensor_parallel_size_vllm }}
              --values {{ gaudi_values_file }}              
            {% endif %}
            {% if ingress_enabled %}
              --set ingress.enabled={{ ingress_enabled }}
              --set ingress.host={{ secret_name }}
              --set ingress.secretname={{ secret_name }}
            {% endif %}
            {% if deploy_keycloak == 'yes' and apisix_enabled %}
              --set oidc.client_id={{ keycloak_client_id | default('') }}
              --set oidc.client_secret={{ client_secret | default('') }}
            {% endif %}
            --force           
          register: helm_upgrade_install_model_deployment
          failed_when: helm_upgrade_install_model_deployment.rc != 0
      run_once: true
      tags: install-deepseek-r1-distill-llama8b
      when:                        
        - "'deepseek-r1-distill-llama8b' in (model_name_list | regex_replace(',', ' ') | split())"
        - install_true == 'true'


    - name: Check if vllm-deepkseek-r1-llama-8b Model is deployed
      ansible.builtin.command:
        cmd: "helm list --filter vllm-deepkseek-r1-llama-8b --short"
      register: helm_release_installed
      ignore_errors: true
      run_once: true
      tags: uninstall-deepseek-r1-distill-llama8b
    - name: Uninstall vllm-deepkseek-r1-llama-8b Model 
      ansible.builtin.command:
        cmd: "helm uninstall vllm-deepkseek-r1-llama-8b"
      run_once: true
      tags: uninstall-deepseek-r1-distill-llama8b
      when:
        - "'deepseek-r1-distill-llama8b' in (model_name_list | regex_replace(',', ' ') | split())"
        - uninstall_true == 'true'
        - helm_release_installed.stdout != ""    

    - name: Deploy Llama3.405b LLM Model
      block:
        - name: Delete Ingress resource Llama3.405b from default namespace
          tags: install-llama3-405b
          kubernetes.core.k8s:
            kind: Ingress
            namespace: default
            name: vllm-llama3-405b-ingress
            state: absent
        - name: Delete Ingress resource Llama3.405b from auth-apisix namespace
          tags: install-llama3-405b
          kubernetes.core.k8s:
            kind: Ingress
            namespace: auth-apisix
            name: vllm-llama3-405b-ingress
            state: absent
        - name: Deploy LLM model Llama3.405b
          ansible.builtin.command: >-
            helm upgrade --install vllm-llama3-405b "{{ remote_helm_charts_base }}/vllm"
            --set LLM_MODEL_ID="meta-llama/Llama-3.1-405B-Instruct"
            --set global.monitoring="{{ vllm_metrics_enabled }}"
            --set svcmonitor.enabled="{{ vllm_metrics_enabled }}"
            --set global.HUGGINGFACEHUB_API_TOKEN={{ hugging_face_token }}
            {% if apisix_enabled %}
              --set apisix.enabled={{ apisix_enabled }}
            {% endif %}
            {% if gaudi_deployment %}
              --set tensor_parallel_size=8
              --values {{ gaudi_values_file }}
            {% endif %}
            {% if ingress_enabled %}
              --set ingress.enabled={{ ingress_enabled }}
              --set ingress.host={{ secret_name }}
              --set ingress.secretname={{ secret_name }}
            {% endif %}
            {% if deploy_keycloak == 'yes' and apisix_enabled %}
              --set oidc.client_id={{ keycloak_client_id | default('') }}
              --set oidc.client_secret={{ client_secret | default('') }}
            {% endif %}
            --force
          register: helm_upgrade_install_model_deployment
          failed_when: helm_upgrade_install_model_deployment.rc != 0
      run_once: true
      tags: install-llama3-405b
      when:
        - "'llama3-405b' in model_name_list"
        - install_true == 'true'

    - name: Check if vllm-llama3-405b Model is deployed
      ansible.builtin.command:
        cmd: "helm list --filter vllm-llama3-405b --short"
      register: helm_release_installed
      ignore_errors: true
      run_once: true
      tags: uninstall-llama3-405b
    - name: Uninstall Llama3.405b Model 
      ansible.builtin.command:
        cmd: "helm uninstall vllm-llama3-405b"
      run_once: true
      tags: uninstall-llama3-405b
      when:
        - "'llama3-405b' in model_name_list"
        - uninstall_true == 'true'
        - helm_release_installed.stdout != ""

    - name: Check if CPU Model is installed
      ansible.builtin.command:
        cmd: "helm list --filter vllm-llama8b-cpu --short"
      register: helm_release_installed
      ignore_errors: true      
      run_once: true
      tags: uninstall-cpu-llama-8b
    - name: Uninstall CPU  Model
      ansible.builtin.command:
        cmd: "helm uninstall vllm-llama8b-cpu"
      run_once: true
      tags: uninstall-cpu-llama-8b
      when:
        - model_name_list is defined
        - "'cpu-llama-8b' in (model_name_list | regex_replace(',', ' ') | split())"
        - uninstall_true == 'true'
        - helm_release_installed.stdout != ""        
    
    - name: Deploy CPU based LLM model  llama 8b
      block:        
        - name: Delete Ingress resource Llama8b from default namespace
          tags: install-cpu-llama-8b
          kubernetes.core.k8s:
            kind: Ingress
            namespace: default
            name: vllm-llama8b-cpu-ingress
            state: absent
        - name: Delete Ingress resource Llama8b from auth-apisix namespace
          tags: install-cpu-llama-8b
          kubernetes.core.k8s:
            kind: Ingress
            namespace: auth-apisix
            name: vllm-llama8b-cpu-ingress
            state: absent
        - name: Deploy CPU based LLM model  llama 8b Installation
          ansible.builtin.command: >-
            helm upgrade --install vllm-llama8b-cpu "{{ remote_helm_charts_base }}/vllm"
            --set LLM_MODEL_ID="meta-llama/Meta-Llama-3.1-8B-Instruct"
            --set global.monitoring="{{ vllm_metrics_enabled }}"
            --set svcmonitor.enabled="{{ vllm_metrics_enabled }}"
            --set global.HUGGINGFACEHUB_API_TOKEN={{ hugging_face_token }}                        
            {% if apisix_enabled %}
              --set apisix.enabled={{ apisix_enabled }}
            {% endif %}
            {% if ingress_enabled %}
              --set ingress.enabled={{ ingress_enabled }}
              --set ingress.host={{ secret_name }}
              --set ingress.secretname={{ secret_name }}
            {% endif %}
            {% if deploy_keycloak == 'yes' and apisix_enabled %}
              --set oidc.client_id={{ keycloak_client_id | default('') }}
              --set oidc.client_secret={{ client_secret | default('') }}
            {% endif %}            
            --force                                                
          register: helm_upgrade_install_model_deployment_cpu_llama8b
          failed_when: helm_upgrade_install_model_deployment_cpu_llama8b.rc != 0          
      run_once: true
      tags: install-cpu-llama-8b
      when:
        - cpu_playbook == 'true'
        - install_true == 'true'
        - model_name_list is defined
        - "'cpu-llama-8b' in (model_name_list | regex_replace(',', ' ') | split())"

    - name: Check if CPU Deepseek R1 Distill Qwen 32b is installed
      ansible.builtin.command:
        cmd: "helm list --filter vllm-deepseek-r1-qwen32b-cpu --short"
      register: helm_release_installed
      ignore_errors: true
      run_once: true
      tags: uninstall-cpu-deepseek-r1-distill-qwen-32b
    - name: Uninstall Deepseek R1 Distill Qwen 32b
      ansible.builtin.command:
        cmd: "helm uninstall vllm-deepseek-r1-qwen32b-cpu"
      run_once: true
      tags: uninstall-cpu-deepseek-r1-distill-qwen-32b
      when:
        - model_name_list is defined
        - "'cpu-deepseek-r1-distill-qwen-32b' in (model_name_list | regex_replace(',', ' ') | split())"            
        - uninstall_true == 'true'
        - helm_release_installed.stdout != ""        
    
    - name: Deploy CPU Deepseek R1 Distill Qwen 32b LLM model
      block:        
        - name: Delete Ingress resource  Deepseek R1 Distill Qwen 32b from default namespace
          tags: install-cpu-deepseek-r1-distill-qwen-32b
          kubernetes.core.k8s:
            kind: Ingress
            namespace: default
            name: vllm-deepseek-r1-qwen32b-cpu-ingress
            state: absent
        - name: Delete Ingress resource  Deepseek R1 Distill Qwen 32b from auth-apisix namespace
          tags: install-cpu-deepseek-r1-distill-qwen-32b
          kubernetes.core.k8s:
            kind: Ingress
            namespace: auth-apisix
            name: vllm-deepseek-r1-qwen32b-cpu-ingress
            state: absent
        - name: Deploy CPU based LLM model Deepseek R1 Distill Qwen 32b Installation
          ansible.builtin.command: >-
            helm upgrade --install vllm-deepseek-r1-qwen32b-cpu "{{ remote_helm_charts_base }}/vllm"
            --set LLM_MODEL_ID="deepseek-ai/DeepSeek-R1-Distill-Qwen-32B"
            --set global.monitoring="{{ vllm_metrics_enabled }}"
            --set svcmonitor.enabled="{{ vllm_metrics_enabled }}"
            --set global.HUGGINGFACEHUB_API_TOKEN={{ hugging_face_token }}                        
            {% if apisix_enabled %}
              --set apisix.enabled={{ apisix_enabled }}
            {% endif %}
            {% if ingress_enabled %}
              --set ingress.enabled={{ ingress_enabled }}
              --set ingress.host={{ secret_name }}
              --set ingress.secretname={{ secret_name }}
            {% endif %}
            {% if deploy_keycloak == 'yes' and apisix_enabled %}
              --set oidc.client_id={{ keycloak_client_id | default('') }}
              --set oidc.client_secret={{ client_secret | default('') }}
            {% endif %}            
            --force                                                
          register: helm_upgrade_install_model_deployment_cpu_deepseek_qwen32b
          failed_when: helm_upgrade_install_model_deployment_cpu_deepseek_qwen32b.rc != 0
      run_once: true
      tags: install-cpu-deepseek-r1-distill-qwen-32b
      when:
        - model_name_list is defined
        - cpu_playbook == 'true'
        - install_true == 'true' 
        - "'cpu-deepseek-r1-distill-qwen-32b' in (model_name_list | regex_replace(',', ' ') | split())"

    - name: Check if CPU Deepseek R1 Distill Llama 8B is installed
      ansible.builtin.command:
        cmd: "helm list --filter vllm-deepseek-r1-llama8b-cpu --short"
      register: helm_release_installed
      ignore_errors: true
      run_once: true
      tags: uninstall-cpu-deepseek-r1-distill-llama8b
    - name: Uninstall Deepseek R1 Distill Llama 8B
      ansible.builtin.command:
        cmd: "helm uninstall vllm-deepseek-r1-llama8b-cpu"
      run_once: true
      tags: uninstall-cpu-deepseek-r1-distill-llama8b
      when:                
        - "'cpu-deepseek-r1-distill-llama8b' in (model_name_list | regex_replace(',', ' ') | split())"
        - uninstall_true == 'true'        
        - helm_release_installed.stdout != ""        
    
    - name: Deploy CPU Deepseek R1 Distill Llama 8B LLM model
      block:        
        - name: Delete Ingress resource Deepseek R1 Distill Llama 8B from default namespace
          tags: install-cpu-deepseek-r1-distill-llama8b
          kubernetes.core.k8s:
            kind: Ingress
            namespace: default
            name: vllm-deepseek-r1-llama8b-cpu-ingress
            state: absent
        - name: Delete Ingress resource Deepseek R1 Distill Llama 8B from auth-apisix namespace
          tags: install-cpu-deepseek-r1-distill-llama8b
          kubernetes.core.k8s:
            kind: Ingress
            namespace: auth-apisix
            name: vllm-deepseek-r1-llama8b-cpu-ingress
            state: absent
        - name: Deploy CPU based LLM model Deepseek R1 Distill Llama 8B Installation
          ansible.builtin.command: >-
            helm upgrade --install vllm-deepseek-r1-llama8b-cpu "{{ remote_helm_charts_base }}/vllm"
            --set LLM_MODEL_ID="deepseek-ai/DeepSeek-R1-Distill-Llama-8B"
            --set global.monitoring="{{ vllm_metrics_enabled }}"
            --set svcmonitor.enabled="{{ vllm_metrics_enabled }}"
            --set global.HUGGINGFACEHUB_API_TOKEN={{ hugging_face_token }}                        
            {% if apisix_enabled %}
              --set apisix.enabled={{ apisix_enabled }}
            {% endif %}
            {% if ingress_enabled %}
              --set ingress.enabled={{ ingress_enabled }}
              --set ingress.host={{ secret_name }}
              --set ingress.secretname={{ secret_name }}
            {% endif %}
            {% if deploy_keycloak == 'yes' and apisix_enabled %}
              --set oidc.client_id={{ keycloak_client_id | default('') }}
              --set oidc.client_secret={{ client_secret | default('') }}
            {% endif %}            
            --force                                                
          register: helm_upgrade_install_model_deployment_cpu_deepseek_llama_8b
          failed_when: helm_upgrade_install_model_deployment_cpu_deepseek_llama_8b.rc != 0          
      run_once: true
      tags: install-cpu-deepseek-r1-distill-llama8b
      when:
        - cpu_playbook == 'true'
        - install_true == 'true'         
        - "'cpu-deepseek-r1-distill-llama8b' in (model_name_list | regex_replace(',', ' ') | split())"
 
    - name: List of Models to be Installed
      tags: always
      run_once: true
      debug:
        var: model_name_list
        
    - name: List the Installed Inference Models
      ansible.builtin.shell:
        cmd: "helm list --short | grep 'vllm-'"
      register: inference_models
      when: list_model_true == 'true'
    - name: Print Installed Models in Comma Separated Format
      ansible.builtin.debug:
        msg: "Installed Models: {{ inference_models.stdout_lines | join(', ') }}"
      when: inference_models.stdout_lines is defined and inference_models.stdout_lines | length > 0
    
    - name: Clean up remote dependencies directory
      tags: always
      ansible.builtin.file:
        path: "{{ remote_helm_charts_base }}"
        state: absent
